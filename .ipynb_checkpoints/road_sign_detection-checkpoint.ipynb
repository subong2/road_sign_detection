{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "incoming-decision",
   "metadata": {},
   "outputs": [],
   "source": [
    "#library imports\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "prospective-heavy",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "female-constitutional",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = Path('./Datasets/images')\n",
    "anno_path = Path('./Datasets/annotations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "designing-occasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filelist(root, file_type):\n",
    "    \"\"\"Returns a fully-qualified list of filenames under root directory\"\"\"\n",
    "    return [os.path.join(directory_path, f) for directory_path, directory_name, \n",
    "            files in os.walk(root) for f in files if f.endswith(file_type)]\n",
    "\n",
    "def generate_train_df (anno_path):\n",
    "    annotations = filelist(anno_path, '.xml')\n",
    "    anno_list = []\n",
    "    for anno_path in annotations:\n",
    "        root = ET.parse(anno_path).getroot()\n",
    "        anno = {}\n",
    "        anno['filename'] = Path(str(images_path) + '/'+ root.find(\"./filename\").text)\n",
    "        anno['width'] = root.find(\"./size/width\").text\n",
    "        anno['height'] = root.find(\"./size/height\").text\n",
    "        anno['xmin'] = int(root.find(\"./object/bndbox/xmin\").text)\n",
    "        anno['ymin'] = int(root.find(\"./object/bndbox/ymin\").text)\n",
    "        anno['xmax'] = int(root.find(\"./object/bndbox/xmax\").text)\n",
    "        anno['ymax'] = int(root.find(\"./object/bndbox/ymax\").text)\n",
    "        anno['class'] = root.find(\"./object/name\").text\n",
    "        anno_list.append(anno)\n",
    "    return pd.DataFrame(anno_list)\n",
    "\n",
    "# 편의상 class를 뒤로 뺌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "textile-resistance",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = generate_train_df(anno_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "progressive-assessment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label encode target\n",
    "class_dict = {'speedlimit': 0, 'stop': 1, 'crosswalk': 2, 'trafficlight': 3}\n",
    "df_train['class'] = df_train['class'].apply(lambda x:  class_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "initial-parade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(877, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Datasets/images/road712.png</td>\n",
       "      <td>300</td>\n",
       "      <td>400</td>\n",
       "      <td>98</td>\n",
       "      <td>140</td>\n",
       "      <td>139</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Datasets/images/road706.png</td>\n",
       "      <td>300</td>\n",
       "      <td>400</td>\n",
       "      <td>136</td>\n",
       "      <td>92</td>\n",
       "      <td>177</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Datasets/images/road289.png</td>\n",
       "      <td>300</td>\n",
       "      <td>400</td>\n",
       "      <td>61</td>\n",
       "      <td>140</td>\n",
       "      <td>146</td>\n",
       "      <td>227</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Datasets/images/road538.png</td>\n",
       "      <td>300</td>\n",
       "      <td>400</td>\n",
       "      <td>115</td>\n",
       "      <td>169</td>\n",
       "      <td>149</td>\n",
       "      <td>205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Datasets/images/road510.png</td>\n",
       "      <td>300</td>\n",
       "      <td>400</td>\n",
       "      <td>89</td>\n",
       "      <td>201</td>\n",
       "      <td>133</td>\n",
       "      <td>245</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      filename width height  xmin  ymin  xmax  ymax  class\n",
       "0  Datasets/images/road712.png   300    400    98   140   139   182      0\n",
       "1  Datasets/images/road706.png   300    400   136    92   177   135      0\n",
       "2  Datasets/images/road289.png   300    400    61   140   146   227      1\n",
       "3  Datasets/images/road538.png   300    400   115   169   149   205      0\n",
       "4  Datasets/images/road510.png   300    400    89   201   133   245      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-zoning",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
