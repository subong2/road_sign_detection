{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "configured-event",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "characteristic-mailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = Path('./Datasets/images')\n",
    "anno_path = Path('./Datasets/annotations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "unable-exchange",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filelist(root, file_type):\n",
    "    \"\"\"Returns a fully-qualified list of filenames under root directory\"\"\"\n",
    "    return [os.path.join(directory_path, f) for directory_path, directory_name, \n",
    "            files in os.walk(root) for f in files if f.endswith(file_type)]\n",
    "\n",
    "def generate_train_df (anno_path):\n",
    "    annotations = filelist(anno_path, '.xml')\n",
    "    anno_list = []\n",
    "    for anno_path in annotations:\n",
    "        root = ET.parse(anno_path).getroot()\n",
    "        anno = {}\n",
    "        anno['filename'] = Path(str(images_path) + '/'+ root.find(\"./filename\").text)\n",
    "        anno['bb_info'] = [int(root.find(\"./object/bndbox/xmin\").text),int(root.find(\"./object/bndbox/ymin\").text),int(root.find(\"./object/bndbox/xmax\").text),int(root.find(\"./object/bndbox/ymax\").text)]\n",
    "        anno['class'] = root.find(\"./object/name\").text\n",
    "        anno_list.append(anno)\n",
    "    return pd.DataFrame(anno_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "handed-optimization",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = generate_train_df(anno_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sporting-western",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>bb_info</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Datasets/images/road712.png</td>\n",
       "      <td>[98, 140, 139, 182]</td>\n",
       "      <td>speedlimit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Datasets/images/road706.png</td>\n",
       "      <td>[136, 92, 177, 135]</td>\n",
       "      <td>speedlimit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Datasets/images/road289.png</td>\n",
       "      <td>[61, 140, 146, 227]</td>\n",
       "      <td>stop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Datasets/images/road538.png</td>\n",
       "      <td>[115, 169, 149, 205]</td>\n",
       "      <td>speedlimit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Datasets/images/road510.png</td>\n",
       "      <td>[89, 201, 133, 245]</td>\n",
       "      <td>speedlimit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>Datasets/images/road535.png</td>\n",
       "      <td>[100, 254, 180, 334]</td>\n",
       "      <td>speedlimit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>Datasets/images/road284.png</td>\n",
       "      <td>[111, 133, 165, 187]</td>\n",
       "      <td>speedlimit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>Datasets/images/road290.png</td>\n",
       "      <td>[105, 157, 171, 224]</td>\n",
       "      <td>speedlimit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>Datasets/images/road723.png</td>\n",
       "      <td>[115, 185, 160, 230]</td>\n",
       "      <td>speedlimit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>Datasets/images/road737.png</td>\n",
       "      <td>[115, 151, 143, 179]</td>\n",
       "      <td>speedlimit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>877 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        filename               bb_info       class\n",
       "0    Datasets/images/road712.png   [98, 140, 139, 182]  speedlimit\n",
       "1    Datasets/images/road706.png   [136, 92, 177, 135]  speedlimit\n",
       "2    Datasets/images/road289.png   [61, 140, 146, 227]        stop\n",
       "3    Datasets/images/road538.png  [115, 169, 149, 205]  speedlimit\n",
       "4    Datasets/images/road510.png   [89, 201, 133, 245]  speedlimit\n",
       "..                           ...                   ...         ...\n",
       "872  Datasets/images/road535.png  [100, 254, 180, 334]  speedlimit\n",
       "873  Datasets/images/road284.png  [111, 133, 165, 187]  speedlimit\n",
       "874  Datasets/images/road290.png  [105, 157, 171, 224]  speedlimit\n",
       "875  Datasets/images/road723.png  [115, 185, 160, 230]  speedlimit\n",
       "876  Datasets/images/road737.png  [115, 151, 143, 179]  speedlimit\n",
       "\n",
       "[877 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "functioning-member",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label encode target\n",
    "class_dict = {'speedlimit': 0, 'stop': 1, 'crosswalk': 2, 'trafficlight': 3}\n",
    "df_train['class'] = df_train['class'].apply(lambda x:  class_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "resident-petite",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "perceived-mumbai",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.ColorJitter(brightness=0.6, contrast=0.6, saturation=0.6, hue=0.6, p=0.4),\n",
    "    A.Resize(height=300, width=447, p=1.0),\n",
    "    ToTensorV2()\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "promotional-banner",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_transform = A.Compose([\n",
    "    A.Resize(height=300, width=447, p=1.0),\n",
    "    ToTensorV2()\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "medieval-illustration",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train[['filename', 'bb_info']]\n",
    "Y = df_train['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "divided-generic",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "humanitarian-capture",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class RoadDataset(Dataset):\n",
    "    def __init__(self, paths, bb, y, transforms=False):\n",
    "        self.transforms = transforms\n",
    "        self.paths = paths.values\n",
    "        self.bb = bb.values\n",
    "        self.y = y.values\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        y_class = self.y[idx]\n",
    "        bb_info = self.bb[idx]\n",
    "        \n",
    "        image = cv2.imread(str(path))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        \n",
    "        if self.transforms:\n",
    "\n",
    "            tf_result = self.transforms(image=image , bboxes=[bb_info], class_labels=y_class)\n",
    "            x = tf_result['image']\n",
    "            y_bb = tf_result['bboxes'][0]\n",
    "            y_bb = torch.tensor(y_bb)\n",
    "\n",
    "        \n",
    "        \n",
    "        return x, y_class, y_bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "absolute-porter",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = RoadDataset(X_train['filename'],X_train['bb_info'] ,y_train, transforms=transform)\n",
    "valid_ds = RoadDataset(X_val['filename'],X_val['bb_info'],y_val,transforms=y_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "established-documentary",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "classical-narrative",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "extended-morrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BB_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BB_model, self).__init__()\n",
    "        resnet = models.resnet34(pretrained=True)\n",
    "        layers = list(resnet.children())[:8]\n",
    "        self.features1 = nn.Sequential(*layers[:6])\n",
    "        self.features2 = nn.Sequential(*layers[6:])\n",
    "        self.classifier = nn.Sequential(nn.BatchNorm1d(512), nn.Linear(512, 4))\n",
    "        self.bb = nn.Sequential(nn.BatchNorm1d(512), nn.Linear(512, 4))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features1(x)\n",
    "        x = self.features2(x)\n",
    "        x = F.relu(x)\n",
    "        x = nn.AdaptiveAvgPool2d((1,1))(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        return self.classifier(x), self.bb(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "biblical-gambling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_optimizer(optimizer, lr):\n",
    "    for i, param_group in enumerate(optimizer.param_groups):\n",
    "        param_group[\"lr\"] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "coordinate-ocean",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epocs(model, optimizer, train_dl, val_dl, epochs=10,C=1000):\n",
    "    idx = 0\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        total = 0\n",
    "        sum_loss = 0\n",
    "        for x, y_class, y_bb in train_dl:\n",
    "            batch = y_class.shape[0]\n",
    "            x = x.float() / 255\n",
    "            y_class = y_class\n",
    "            y_bb = y_bb\n",
    "            out_class, out_bb = model(x)\n",
    "            loss_class = F.cross_entropy(out_class, y_class, reduction=\"sum\")\n",
    "            \n",
    "            loss_bb = F.l1_loss(out_bb, y_bb, reduction=\"none\").sum(1)\n",
    "                 \n",
    "            loss_bb = loss_bb.sum()\n",
    "            loss = loss_class + loss_bb/C\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            idx += 1\n",
    "            total += batch\n",
    "            sum_loss += loss.item()\n",
    "        train_loss = sum_loss/total\n",
    "        val_loss, val_acc = val_metrics(model, valid_dl, C)\n",
    "        print(\"train_loss %.3f val_loss %.3f val_acc %.3f\" % (train_loss, val_loss, val_acc))\n",
    "    return sum_loss/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "accepted-pastor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_metrics(model, valid_dl, C=1000):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    correct = 0 \n",
    "    for x, y_class, y_bb in valid_dl:\n",
    "        batch = y_class.shape[0]\n",
    "        x = x.float() / 255\n",
    "        y_class = y_class\n",
    "        y_bb = y_bb\n",
    "        out_class, out_bb = model(x)\n",
    "        loss_class = F.cross_entropy(out_class, y_class, reduction=\"sum\")\n",
    "        \n",
    "        loss_bb = F.l1_loss(out_bb, y_bb, reduction=\"none\").sum(1)\n",
    "        \n",
    "        loss_bb = loss_bb.sum()\n",
    "        loss = loss_class + loss_bb/C\n",
    "        _, pred = torch.max(out_class, 1)\n",
    "        correct += pred.eq(y_class).sum().item()\n",
    "        sum_loss += loss.item()\n",
    "        total += batch\n",
    "    return sum_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "female-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BB_model()\n",
    "parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = torch.optim.Adam(parameters, lr=0.006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-inquiry",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 2.584 val_loss 364059.312 val_acc 0.057\n",
      "train_loss 1.779 val_loss 396.109 val_acc 0.727\n",
      "train_loss 1.573 val_loss 9.757 val_acc 0.733\n",
      "train_loss 1.525 val_loss 1.383 val_acc 0.727\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, optimizer, train_dl, valid_dl, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-singapore",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_optimizer(optimizer, 0.001)\n",
    "train_epocs(model, optimizer, train_dl, valid_dl, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-employer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-league",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
